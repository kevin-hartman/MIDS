par(mfrow=c(2,2))
curve(x^3-3*x, -2, 2)
curve(x^2-2, add = TRUE, col = "violet")
par(mfrow=c(2,2))
curve(x^3-3*x, -2, 2)
curve(x^2-2, add = TRUE, col = "violet")
par(mfrow=c(2,2))
curve(x^3-3*x, -2, 2)
curve(x^2-2, add = TRUE, col = "violet")
curve(1-abs(x), -100,1)
curve(0,0,0)
curve(x^2, 0, 1)
curve((1/2*exp(x)), -100, 0)
curve(1-(1/2*exp(-x), add = TRUE, col = "violet")
curve(1-(1/2*exp(-x)), add = TRUE, col = "violet")
curve(1-(1/2*exp(-x)), 0, 100)
par(mfrow=c(2,2))
curve((1/2*exp(x)), -100, 0)
cdf<- function(x) {
if (x < 0) {
return (1/2*exp(x))
} else return 1-(1/2*exp(-x))
}
cdf<- function(x) {
if (x < 0) {
return (1/2*exp(x))
}
else return 1-(1/2*exp(-x))
}
else return (1-(1/2*exp(-x)))
cdf<- function(x) {
if (x < 0) {
return (1/2*exp(x))
}
else {
return (1-(1/2*exp(-x)))
}
}
curve(cdf(x), -100, 100)
xs <- seq(-100, 100, by=1)
res <- mapply(cdf, list(xs))
res <- mapply(cdf, xs)
plot(res)
xs <- seq(-20, 20, by=1)
res <- mapply(cdf, xs)
plot(res)
curve(log(x), -20, 20)
install.packages("effsize")
# setting the seed will ensure different users generate the
# same random draws.
set.seed(898)
# effsize gives us a convenient function for computing Cohen's d
library(effsize)
load("elem94_95.RData")
load("/Documents/GitHub/MIDS/W203/Week9/elem94_95.RData")
load("/Users/Kevin/Documents/GitHub/MIDS/W203/Week9/elem94_95.RData")
head(Schools)
desc
summary(Schools$bs)
hist(Schools$bs, breaks = 50, main = "Histogram of Benefits-to-Salary Ratio",
xlab = NULL)
hist(Schools$bs, breaks = 50, main = "Histogram of Benefits-to-Salary Ratio",
xlab = NULL)
# Let's look at the data points with unusually high bs ratios.
order(Schools$bs, decreasing = T)
head(Schools[ order(Schools$bs, decreasing = T), ])
head(Schools[ order(Schools$avgsal), ])
# We create a binary variable to represent schools with a high
# benefits-to-salary ratio.
ifelse(Schools$bs > mean(Schools$bs),
"high benefits", "low benefits")
Schools$ben = factor(ifelse(Schools$bs > mean(Schools$bs),
"high benefits", "low benefits"))
summary(Schools$ben)
summary(Schools$math4)
hist(Schools$math4, breaks= 50,
main = "Percentage of Students Passing Math Exam",
xlab = NULL)
t.test(math4 ~ ben, data = Schools)
(high_bs_scores = Schools$math4[Schools$ben == "high benefits"])
(low_bs_scores = Schools$math4[Schools$ben == "low benefits"])
t.test(high_bs_scores, low_bs_scores)
by(Schools$avgsal, Schools$ben, mean)
cohen.d(math4 ~ ben, data = Schools)
# We could also calculate the effect size correlation.  This effect
# size measure has a very elegant interpretation.  Since we have
# highben as a grouping variable, the effect size correlation is
# simply the correlation between math4 and our grouping variable.
summary(as.numeric(Schools$ben))
cor(Schools$math4, as.numeric(Schools$ben))
small_samp = Schools[sample(nrow(Schools), 25), ]
summary(small_samp)
hist(small_samp$math4, breaks = 20, main = "Math Passing Rate in Small Sample",
xlab = NULL)
qqnorm(small_samp$math4,
main = "Normal Q-Q Plot for Math Exam Passing Rate")
wilcox.test(math4 ~ ben, data = Schools)
# First, we'll examine the means directly
c(mean(Schools$math4), mean(Schools$story4))
hist(Schools$story4 - Schools$math4, breaks= 50,
main = "Difference between Passing Rates for Reading and Math",
xlab = "reading passing rate minus math passing rate")
t.test(Schools$math4, Schools$story4, paired = T)
t.test(Schools$math4, Schools$story4, paired = F)
install.packages("cookbook")
install.packages("codebook")
