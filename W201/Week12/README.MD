# Week 12 | Data Science Futures & Life as a Data Scientist: Domains, Employers, Projects
* The future of data science: More than Minority Report?
* Ubiquitous data science’s potential ethical and legal issues
* Identify your role in the future of data science: potential employers, roles, and projects.
* Work as a data scientist, including interviews with current data scientists



Async
* [Data Science Futures & Life as a Data Scientist](https://learn.datascience.berkeley.edu/ap/courses/266/sections/63f6d138-9c2e-4d9e-b9b1-4d2e70788eaf/coursework/courseModule/f8ca050b-8af1-461e-a394-61b06523b25e)


Required reading:
* Duhigg, Charles. “How Companies Learn Your Secrets.” New York Times (February 16, 2012). http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html?pagewanted=print
* Nonaka, Ikujiro. [“The Knowledge-Creating Company.”](./The-Knowledge-Creating-Company.pdf) Harvard Business Review (November 1991). http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=9201061306&site=eds-live

Optional reading:
* Marwick, Alice E., & boyd, danah. (2014). [Networked privacy: How teenagers negotiate context in social media(./1461444814543995.pdf). New Media & Society, 16(7), 1051–1067. http://doi.org/10.1177/1461444814543995 


Additional video:
* Below you can find a short youtube video that will supplement my overview at the beginning of class. You must be signed into your bmail account to view the video. [Week 12 Mike Overview (Video)](https://youtu.be/2127NholFjs)
* I recommend you familiarize yourself with the most up to date information on the EU General Data Protection Regulation (GDPR) and how US companies are responding; this will likely have broad impacts on data science.

Async video questions:
* “Data mining gone bad”
* What is privacy?
* How do we determine the line between personalization of services and invasion of privacy? What level of personalization are we comfortable with?
* How much power do we want to endow technology with? (e.g. Robots that can assemble other robots; Software code that writes other software code)

Additional takeaways:
* Questions to help you digest readings 
  * Nonaka, Ikujiro. “The Knowledge-Creating Company.” Harvard Business Review (November 1991).
    * A) “When information differentials exists, members of an organization can no longer interact on equal terms, which hinders the search for different interpretations of knowledge...All company information (with the exception of personnel data) is stored in a single integrated database, open to any employee regardless of position” (Nonaka, p.102).
      * How common is this democratization of data? Does this involve a great deal of trust? (i.e. too much trust). What are some potential advantages of this approach? What are some potential liabilities? 
    * B) Conflict in knowledge-creating companies is good. “…dialogue can—indeed, should—involve considerable conflict and disagreement. It is precisely such conflict that pushes employees to question existing premises and make sense of their experience in a new way” (Nonaka, p104).
      * How do you embrace this philosophy but avoid a state of complete disarray?
    * C) “The fundamental principle of organization design at the Japanese companies I have studied is redundancy--the conscious overlapping of company information, business activities, and managerial responsibilities” (Nonaka, p102).
      * Do well-trained data scientists, who excel at technical and communication skills, embody this redundancy? Is redundancy of responsibilities inefficient? How does you company address redundancy?

  * Duhigg, Charles. “How Companies Learn Your Secrets.” New York Times (February 16, 2012).
    * “…when some customers were going through a major life event, like graduating from college or getting a new job or moving to a new town, their shopping habits become flexible in ways that were both predictable and potential gold mines for retailers”
    * “…when parents are exhausted and overwhelmed their shopping patterns and brand loyalties are up for grabs."
      * Are their ethical concerns if a company wants to target people at vulnerable times?
      * Are there ethical concerns if one wants to capture vulnerable populations? (e.g. less abled populations, youth, elderly, etc)
      * How concerned are you with the public “finding out” what data you all collect and how you use it? Does it matter? Are you covered because the consumer agreed to the terms and conditions or because you work for a government agency?

  * optional : Marwick, Alice E., & boyd, danah. (2014). Networked privacy: How teenagers negotiate context in social media. New Media & Society , 16(7), 1051–1067.
    * "The onus is placed on the individual to understand and adjust their settings and practices accordingly” (Marwick and boyd: 2014, p 1062).
      * What is privacy? What obligation do data scientists have to maintain privacy and inform customers about privacy settings? What responsibility do individuals have to understand and manage their privacy?
	* Should companies use social media and other information that an individual perceives is private to evaluate prospective employees? Should current employees be held responsible for what they post online? If so, where do you draw the line? (e.g. racist or prejudicial posts)
    * Think outside of the employment context.
      * People intend to share some information (e.g. picture, post, etc.) only with their friends, but given their friends’ privacy settings the information may effectively become public. What responsibility do data scientists have to keep information “private”?


Discussion Questions:
* In-class presentations
