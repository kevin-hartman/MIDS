{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Unit 5 Homework</h1>\n",
    "<h3> W203 Statistics for Data Science </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unladen Swallows\n",
    "\n",
    "In the async lecture, we built a model consisting of two random variables: Let W represent the wingspan of a swallow, and V represents the velocity.\n",
    "\n",
    "We assume W has a normal distribution with mean 10 and standard deviation 4.\n",
    "\n",
    "We assume that $V = 0.5 \\cdot W + U$, where $U$ is a random variable (which we might call error).  We assume that $U$ has a standard normal distribution and is independent of $W$.\n",
    "\n",
    "Using properties of variance and covariance, derive each element of the variance-covariance matrix for W and V.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Givens**\n",
    "\n",
    ">$\\mu_w = 10 \\quad \\text{and} \\quad \\sigma_w = 4$\n",
    ">\n",
    ">The unladen swallow can be represented as a vector of random variables that are jointly distributed.\n",
    ">\n",
    ">$$\\vec{S} = \\begin{bmatrix} W \\\\ V \\end{bmatrix}$$\n",
    ">\n",
    ">The variance-covariance matrix of $\\vec{S}$ is described by\n",
    ">\n",
    ">$$Var(\\vec{S}) = Var(W,V) = \\begin{bmatrix} Var(W) & Cov(W,V) \\\\ Cov(V,W) & Var(V) \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "\n",
    "Step 1. Calculate Var(W)\n",
    ">\n",
    ">$\\quad Var(W) = \\sigma_w^2 = 4^2 = 16$ \n",
    ">\n",
    "$$Var(\\vec{S}) = \\begin{bmatrix} 16 & Cov(W,V) \\\\ Cov(V,W) & Var(V) \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Calculate Var(V) by substituting $V = 0.5W + U$\n",
    ">\n",
    ">$\\quad Var(V) = Var(0.5W + U)$\n",
    ">\n",
    ">Since U is independent of W, we can use $Var(X+Y) = Var(X) + Var(Y)$\n",
    ">\n",
    ">$\\quad Var(V) = Var(0.5W) + Var(U)$\n",
    ">\n",
    ">Since U is a standard normal distribution with $\\mu_u = 0 \\text{ and } \\sigma_u = 1 \\text{, we know that } Var(U) = \\sigma_u^2 = 1$\n",
    ">\n",
    ">$\\quad Var(V) = Var(0.5W) + 1$\n",
    ">\n",
    ">$\\quad Var(V) = E\\big[(0.5W)^2\\big] - \\big[E(0.5W)\\big]^2 + 1$\n",
    ">\n",
    ">$\\quad Var(V) = E(0.25W^2) - \\big[E(0.5W)\\big]^2 + 1$\n",
    ">\n",
    ">$\\quad Var(V) = 0.25E(W^2) - \\big[0.5E(W)\\big]^2 + 1$\n",
    ">\n",
    ">To substitute $E(W^2)$, we were given $\\sigma_w = 4 \\quad \\text{ and } \\quad Var(W) = 16 \\quad and \\quad \\mu_w =E(W) = 10$\n",
    ">\n",
    ">$\\quad Var(W) = E(W^2) - \\big[E(W)\\big]^2 = 16$\n",
    ">\n",
    ">$\\quad E(W^2) = 16 + \\big[E(W)\\big]^2 = 16 + 10^2 = 116$\n",
    ">\n",
    ">Solving for Var(V) becomes\n",
    ">\n",
    ">$\\quad Var(V) = 0.25(116) - \\big[0.5 \\cdot 10\\big]^2 + 1$\n",
    ">\n",
    ">$\\quad Var(V) = 29 - 5^2 + 1 = 29 - 25 + 1 = 5$\n",
    ">\n",
    "$$Var(\\vec{S}) = \\begin{bmatrix} 16 & Cov(W,V) \\\\ Cov(V,W) & 5 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Calculate Cov(W,V) by substituting $V=0.5W + U$\n",
    ">\n",
    ">$\\quad Cov(W,V) = Cov(W,0.5W + U)$\n",
    ">\n",
    ">Since $Cov(X,Y+Z) = Cov(X,Y) + Cov(X,Z)$\n",
    ">\n",
    ">$\\quad Cov(W,V) = Cov(W,0.5W) + Cov(W,U)$\n",
    ">\n",
    ">For $Cov(W,0.5W)$:\n",
    ">\n",
    ">$\\quad Cov(W, 0.5W) = E\\big[\\big(W-\\mu_w\\big)\\big(0.5W-0.5\\mu_w\\big)\\big]$\n",
    ">\n",
    ">$\\quad \\quad = E\\big[\\big(W-\\mu_w)\\big)\\cdot 0.5\\big(W-\\mu_w)\\big)\\big]$\n",
    ">\n",
    ">$\\quad \\quad = E\\big[0.5\\big(W-\\mu_w)\\big)^2\\big]$\n",
    ">\n",
    ">$\\quad \\quad = 0.5E\\big[\\big(W-\\mu_w\\big)^2\\big]$\n",
    ">\n",
    ">$\\quad \\quad = 0.5 \\cdot Var(W)$\n",
    ">\n",
    ">$\\quad \\quad = 0.5 \\cdot 16 = 8$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">For $Cov(W,U)$:\n",
    ">\n",
    ">$\\quad Cov(W, U) = E\\big[\\big(W-\\mu_w)\\big)\\big(U-\\mu_u)\\big)\\big]$\n",
    ">\n",
    ">$\\quad = E(WU) - \\mu_w E(U)$\n",
    ">\n",
    ">Since U and W are independent, $E(XY) = E(X) \\cdot E(Y)$\n",
    ">\n",
    ">$\\quad = E(W)E(U) - E(W)E(U) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    ">$\\quad \\quad = E\\big[\\big(W-10\\big)\\big(0.5W-0.5(10)\\big)\\big]$\n",
    ">\n",
    ">$\\quad \\quad = E\\big[0.5W^2  -W \\cdot E(W) + .5[E(W)]^2\\big]$\n",
    ">\n",
    ">$\\quad \\quad = E\\big[0.5W^2  -W \\cdot 10 + .5[10]^2\\big]$\n",
    ">\n",
    ">$\\quad \\quad = E\\big[0.5W^2  -10W + 50\\big]$\n",
    ">\n",
    ">$\\quad \\quad = .5E(W^2) -10E(W) + 50$\n",
    ">\n",
    ">$\\quad \\quad = .5(116) -10(10) + 50$\n",
    ">\n",
    ">$\\quad \\quad = 58 - 100 + 50 = 8$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relating Min and Max\n",
    "\n",
    "Continuous random variables $X$ and $Y$ have a joint distribution with probability density function,\n",
    "\n",
    "$$ f(x,y) = \\begin{cases}\n",
    "2, &0 < y < x < 1 \\\\\n",
    "0, &otherwise.\n",
    "\\end{cases} $$\n",
    "\n",
    "You may wonder where you would find such a distribution.  In fact, if $A_1$ and $A_2$ are independent random variables uniformly distributed on $[0,1]$, and you define $X = max(A_1,A_2)$, $Y = min(A_1,A_2)$, then $X$ and $Y$ will have exactly the joint distribution defined above.\n",
    "\n",
    "a. Draw a graph of the region for which $X$ and $Y$ have positive probability density.\n",
    "\n",
    "b. Derive the marginal probability density function of $X$, $f_X(x)$.  Make sure you write down a complete expression.\n",
    "\n",
    "c. Derive the unconditional expectation of $X$.\n",
    "\n",
    "d. Derive the conditional probability density function of $Y$, conditional on $X$, $f_{Y|X}(y|x)$\n",
    "\n",
    "e. Derive the conditional expectation of $Y$, conditional on $X$, $E(Y|X)$.\n",
    "\n",
    "f. Derive $E(XY)$.  Hint: if you take an expectation conditional on $X$, $X$ is just a constant inside the expectation.  This means that $E(XY|X) = XE(Y|X)$.\n",
    "\n",
    "g. Using the previous parts, derive $cov(X,Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great Time to Watch Async\n",
    "\n",
    "Suppose your waiting time in minutes for the Caltrain in the morning is uniformly distributed on [0, 5], whereas waiting time in the evening is uniformly distributed on [0, 10].  Each waiting time is independent of all other waiting times.\n",
    "\n",
    "a. If you take the Caltrain each morning and each evening for 5 days in a row, what is your total expected waiting time?\n",
    "\n",
    "b. What is the variance of your total waiting time?\n",
    "\n",
    "c. What is the expected value of the difference between the total evening waiting time and the total morning waiting time over all 5 days?\n",
    "\n",
    "d. What is the variance of the difference between the total evening waiting time and the total morning waiting time over all 5 days?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximizing Correlation\n",
    "\n",
    "Show that if $Y = aX + b$ where $X$ and $Y$ are random variables and $a \\neq 0$, $corr(X,Y) = -1$ or $+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge Problem: Working with Poisson Variables\n",
    "\n",
    "A Poisson random variable $M$ is a discrete random variable with probability mass function given by \n",
    "\n",
    "$$ P_M(m)= \\frac{\\alpha^m}{m!} e^{-\\alpha}, m = 0,1,2,... $$\n",
    "\n",
    "Where $\\alpha$ is a parameter.\n",
    "\n",
    "Let $N$ be another random variable that, conditional on $M=m$, is equally likely to take on any value in the set ${0,1,2,...,m}$\n",
    "\n",
    "a. Find the joint PMF of $M$ and $N$ \n",
    "\n",
    "b. Find the marginal PMF of $N$, $P_N(n)$\n",
    "\n",
    "c. Explain the significance of $N$ in terms of a Poisson process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
