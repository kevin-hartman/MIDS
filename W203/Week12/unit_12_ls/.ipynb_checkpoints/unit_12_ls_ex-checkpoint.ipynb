{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Unit 12 Live Session </center> </h1>\n",
    "<h3> W203 Instructional Team </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Multivariate Linear Regression, Inference </h2>\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1R6LP-gH70o1NB16YJ_lsNcGtkGqa7bpS\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 0.1 Class Announcements </h3>\n",
    "1. Announcement 1\n",
    "2. Packages\n",
    "<ul>\n",
    "<li> conda install -c r r-car\n",
    "<li> conda install -c r r-lmtest\n",
    "<li> conda install -c r r-sandwich\n",
    "<li> conda install -c r r-stargazer\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 0.2 Getting to This Document</h3>\n",
    "\n",
    "If you have not cloned the unit_9_ls repo yet then on the command line\n",
    "\n",
    "1. git clone https://github.com/w203-summer-19/unit_12_ls.git \n",
    "\n",
    "2. cd unit_12_ls\n",
    "\n",
    "3. git checkout penner_sections\n",
    "\n",
    "\n",
    "If you have cloned this repo already then on the command line\n",
    "\n",
    "1. cd unit_12_ls\n",
    "\n",
    "2. git fetch\n",
    "\n",
    "3. git checkout penner_sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1 Useful functions in R: </h3>\n",
    "\n",
    "Code    |    Function \n",
    "--------------------------|---------------------------------------------------------------------\n",
    "coefficients(fit) | Extract model coefficients\n",
    "fitted(fit)       | Extract predicted values\n",
    "residuals(fit)    | Extract resduals\n",
    "vcovHC(fit)       | Extract heteroskedasticity-robust covariance matrix\n",
    "coeftest(fit, vcov = vcovHC) | Conduct hypothesis test with heteroskedasticity-robust standard errors\n",
    "confint(fit, level=0.95)| Calculate non-robust CIs for model parameters (at 95%) \n",
    "\n",
    "**Note:** For heteroskedasticity-robust confidence intervals, get the variance of each coefficient from vcovHC, take the square root to get the standard error, get the proper t critical values from qt, and construct manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2 Variance of OLS Estimators </h3>\n",
    "\n",
    "Recall (one of) the expression(s) for the variance of each OLS slope coefficient:\n",
    "\n",
    "$$var(\\hat{\\beta_j}) = \\frac{\\sigma^2}{SST_j (1-R_j^2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> A Crappy Analogy </h4>\n",
    "\n",
    "Sometimes when you are (re)learning linear regression it is helpful to think in terms of analogies, so here goes... \n",
    "\n",
    "Imagine that you have gone to popular club late on a Friday night with two friends Alex and Bob. You find yourself a table and sit down close to the dance floor. This would be the perfect opportunity for you to try out the new shopping cart dance move you have been practicing in front of your dog all week but its been a long night and the three of you only want to talk.\n",
    "\n",
    "Your conversation starts but you are having trouble following the conversation for two distinct reasons. \n",
    "\n",
    "1. You are having trouble distinguishing the voices of your friends from the overall noise in the club. \n",
    "\n",
    "2. The lights are flashing in such a way that the faces of your friends are in total darkness most of the time, as a result even when you can distinguish between the background club noises and your friends you are having trouble distinguishing Alex's voice from Bob's. \n",
    "\n",
    "The background noise in the club is analogous to the error term $u$ of the regression,\n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + u $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X_1$ and $X_2$ are the variation of $Y$ (the sound in the club) due to Alex and Bob respectively, $u$ is the variation in your outcome $Y$ (sound in the club) which is just uninteresting noise. \n",
    "\n",
    "In this context regression is an attempt to distinguish the variation in $Y$ (sound in the club) due to regressors $X_1$ and $X_2$, (Alex and Bob respectively) from $u$,which is just uninteresting noise (Boots and Pants, \"it's getting hot in here so ....\", \" Yeah, yeah, ... \", \" oh my good she is such a ....\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is also an attempt to distinguish the variation in $Y$ (sound in the club) due to $X_1$ (Alex) from the variation in $Y$ due to $X_2$ (Bob).\n",
    "\n",
    "As a result, here we will equate the variance of the sampling distribution of $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$ with how well you can distinguish the Alex and Bobs voices (respectively) from the rest of the noise of the club, meaning that as the variance decreases the better you can distinguish its source. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://imgflip.com/i/2ekbxi\"><img src=\"https://i.imgflip.com/2ekbxi.jpg\" title=\"made at imgflip.com\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1 ** Why is it desirable to have a small variance for each estimated coefficient? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.2 **  For each component of this equation, explain (1) what it means, and (2) why it moves the standard error of $\\beta_j$ up or down. Try to explain it in terms of the analogy we have constructed.\n",
    "\n",
    "* $\\sigma^2$\n",
    "* $SST_j$\n",
    "* $R_j^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Suppose we have already estimated the following equation \n",
    "\n",
    "$$ Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + u_i $$\n",
    "\n",
    "If we include a new regressor, $Z_i$ that is correlated with $Y_i$ but is independent of both $X_{1i}$ and $X_{2i}$ what do we expect will happen to $V(\\hat{\\beta_1})$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4** Suppose we have already estimated the following equation \n",
    "\n",
    "$$ Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + u_i $$\n",
    "\n",
    "If we include a new regressor, $W_i$ that is uncorrelated with $Y_i$ but is correlated with $X_{1i}$ what do we expect will happen to $V(\\hat{\\beta_1})$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** Did leaving either $Z_i$ or $W_i$ of the original regressions in 2.3 and 2.4 violate any of the CLM assumptions? Why or Why Not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 3 has a special name: the Variance Inflation Factor.  You can find the variance inflation factor for each variable in a linear model using the vif function in the car package.  Interpreting VIFs depends very much on context, but a VIF of 10 would usually be considered very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the variance of each coefficient in R, we would typically get the diagonal elements of the robust covariance matrix, diag(vcovHC(model))\n",
    "\n",
    "To get the standard error of a coefficient, take the square root of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3 R Exercise </h3>\n",
    "\n",
    "In this analysis, we will use the mtcars dataset which is a dataset that was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973-74 models). The dataset is automatically available when you start R.  For more information about the dataset, use the R command: help(mtcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: zoo\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Please cite as: \n",
      "\n",
      " Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n",
      " R package version 5.2.1. https://CRAN.R-project.org/package=stargazer \n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(car)\n",
    "library(lmtest)\n",
    "library(sandwich)\n",
    "library(stargazer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.1 ** Using the mtcars data, run a multiple linear regression to find the effect of displacement (disp), gross horsepower (hp), weight (wt), and rear axle ratio (drat) on the miles per gallon (mpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.2: ** For ** each ** of the following 6 CLM assumptions, assess whether the assumption holds.  Where possible, demonstrate multiple ways of assessing an assumption.  When an assumption appears violated, state what steps you would take in response.\n",
    "\n",
    "1. Linear population model\n",
    "2. Random Sampling\n",
    "3. No perfect multicollinearity\n",
    "4. Zero-conditional mean\n",
    "5. Homoskedasticity\n",
    "6. Normality of Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.3 ** In addition to the above, assess to what extent (imperfect) multicollinearity is affecting your inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.4 ** Interpret your slope coefficients, and note which ones are significantly different from zero.  Whether or not you detected heteroskedasticity above, be conservative in this step and use robust standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5** How does the log transform affect which CLM assumptions hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.6 ** Which model has a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.7 ** (As time allows) Report the results of both models in a nicely formatted regression table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4 More about Multicollinearity </h3>\n",
    "\n",
    "A common problem with multivariate regression is collinearity.\n",
    "If two or more predictor variables are highly correlated, and they are both entered into a regression model, it increases the standard error of each one and you get very unstable estimates of the slope. We usually assess the collinearity by variance inflation factor (VIF). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4> 4.1 Ways to Detect Multicollinearity </h4>\n",
    "\n",
    "We begin by regressing a particular independent variable on all other independent variables.\n",
    "\n",
    "1.) As the squared correlation (r2) increases toward 1.0, the magnitude of potential problems associated with multicollinearity increases correspondingly. \n",
    "\n",
    "\n",
    "2.) Tolerance (1-R2) One minus the squared multiple correlation of a given IV from other Ivs in the equation. Tolerance values of 0.10 or less Indicate that there may be serious multicollinearity. \n",
    "\n",
    "\n",
    "3.) The Variance Inflation Factor [VIF=1/(1-R2)] VIF Is the reciprocal of the Tolerance. Any VIF of 10 or more provides evidence of serious multicollinearity. \n",
    "\n",
    "\n",
    "4.) Condition Number (k) The square root of the ratio of the largest eigenvalue to the smallest eigenvalue. k of 30 or larger indicate that there may be serious multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
