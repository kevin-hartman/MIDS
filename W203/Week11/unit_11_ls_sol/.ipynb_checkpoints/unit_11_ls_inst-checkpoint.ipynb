{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Unit 11 Live Session </center> </h1>\n",
    "<h3> W203 Instructional Team </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Multivariate Linear Regression, Endogeneity, Omitted Variable Bias </h2>\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1N5fK4fZNhJy2TOiEH8I7P9t5U-BPQxOt\"> </img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 0.1 Class Announcements </h3>\n",
    "1. Announcement 1\n",
    "2. Announcement 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 0.2 Getting to This Document</h3>\n",
    "\n",
    "If you have not cloned the unit_11_ls_sol repo yet then on the command line\n",
    "\n",
    "1. git clone https://github.com/w203-spring-19/unit_11_ls_sol.git \n",
    "\n",
    "2. cd unit_11_ls_sol\n",
    "\n",
    "\n",
    "If you have cloned this repo already then on the command line\n",
    "\n",
    "1. cd unit_11_ls_sol\n",
    "\n",
    "2. git fetch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1 Multiple Regression Population Model </h3>\n",
    "\n",
    "In order for the the coefficients in a multiple regression to have favorable properties, we need four assumptions, which are extension of the assumptions we learned for simple regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1**  What are these four assumptions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Linear in Parameters\n",
    "> 2. Random (i.i.d) Sampling\n",
    "> 3. No Perfect Multicollinearity\n",
    "> 4. Zero Conditional Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.2 ** What are the implications of each of these four assumptions, both conceptually and mathematically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Linear in Parameters:* \n",
    "The TRUE relationship between $Y$ and $X$ is linear i.e. the model is correctly specified. More times than not this assumption is not justified in any cogent way other than \"thats what everybody else does\" and \"stop trying to make me use statistical techniques from this millenium!\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Random (i.i.d) Sampling:* If the sampling is not i.i.d estimation and inference will be substantially affected if it is not taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *No Perfect Collinearity:* One regressor cannot be equal to a linear combination of anothers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Zero Conditional Mean:* The linear function is a conditional expectation which exists and is unique. this means that there is no functional relationship between X and u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2 Violations of Assumptions </h3>\n",
    "\n",
    "When one or many of the assumptions state above is violated the estimation of the true regression function $E(Y|X)$ will be affected to some degree depending on the severity of the violation, but we cannot expect that R will tell us that there is something wrong and ask us to fix it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1 ** OLS is Just Numerical Optimization\n",
    "\n",
    "At its heart OLS is just an optimization algorithm trying to find the best linear fit to the data. As a result, even under severe violations of the above assumptions R will generate values for each coefficient of the model. \n",
    "\n",
    "However these values will be estimates of parameters that are quite different from what we expect (often there is no meaning to the estimates, its just nonsense).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1 ** Endogeneity\n",
    "\n",
    "One of the most common violations of the above assumption is a violation of the zero conditional mean assumption. i.e. $E(u|X) \\neq 0$ this is a condition call *Endogeneity*. \n",
    " \n",
    "In linear regressions we can still estimate coefficient relatively well under the weaker condition $E(Xu)=0$ or that X and u are uncorrelated.\n",
    "\n",
    "Note this is a 'weaker' assumption since \n",
    "\n",
    "$$ E(u|X) = 0 \\;\\; \\text{ implies } \\;\\;  E(Xu) = 0 \\;\\; \\text{ but } \\;\\; E(Xu) = 0 \\;\\; \\text{ does not imply } \\;\\; E(u|X) = 0  $$\n",
    " \n",
    "The practical consequences of endogeneity is subtle but important,\n",
    "\n",
    "* if $E(u|X) = 0$ then the estimator $\\hat{\\beta}_1$ is unbiased.i.e.\n",
    "\n",
    "$$E(\\hat{\\beta}_1) = \\beta_1$$\n",
    "\n",
    "* if $E(u|X) \\neq 0 $ but $E(Xu) = 0$ then the bias of $\\hat{\\beta}_1$ converges in (probability to zero) as $n \\rightarrow \\infty$ \n",
    "$$ E(\\hat{\\beta}_1) \\neq \\beta_1 \\;\\; \\text{ but } \\;\\; |E(\\hat{\\beta}_1) - \\beta_1| \\stackrel{p}{\\rightarrow} 0  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3 Effect of Endogeneity </h3>\n",
    "\n",
    "So far, we have been interpreting regressions predictively: given the values of several inputs, the fitted model allows us to predict y, considering the n data points as a simple random sample from a hypothetical infinite \"superpopulation\" or probability distribution. Then we can make comparisons across different combinations of values for these inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe that the outcome we care about is associated with an number of explanatory variables.  If we could just write down all of these (correctly) we would have a good idea of how they are related. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$wage = \\beta_0 + \\beta_1 educ + \\beta_2 ability + u$$\n",
    "\n",
    "Here, $u$ is a truly random error.  This model is associative in the sense that if we manipulate educ, increasing it by 1 year, wage will actually go up by $\\beta_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central problem of associative inference is that, even though these causes exist, we can't measure all of them.  Perhaps we can only measure wage and educ:\n",
    "\n",
    "$$wage = \\beta_0 + \\beta_1 educ + w \\tag{1}$$\n",
    "\n",
    "What's the problem with this model?  Solving for $w$, we have,\n",
    "\n",
    "$$w = \\beta_2 ability + u$$\n",
    "\n",
    "We know u is uncorrelated with educ, but what about ability?  People with more ability tend to have more education as well.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "cov(educ, w) &= cov(educ, \\beta_2 ability + u) \\\\\n",
    "&= \\beta_2 cov(educ, ability) >0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This is *endogeneity*.  OLS regression cannot identify $\\beta_1$, because ols can only find the line of best fit - but that's not the line we want!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.1 \"Causality\" The Most Misused Word in Statistics</h3> \n",
    "\n",
    "As we will talk about in unit 14, in order for a researcher to claim that the evidence generated by their study has some kind of causal interpretation requires alot of justification beyond $$E(u|X)=0$$\n",
    "\n",
    "For example does anyone really think that the graduating from your junior year of high school \"causes\" your wages to increase by $\\beta_1$ in the same way that a drug like Lipitor reduces your cholesterol? No of course not, so unless you can justify a model as having a causal interpretation in terms of things like the potential outcome framework, confounding, and selection bias please stick to associative interpretations.\n",
    "\n",
    "For more on this wait till unit 14 and/or take W241.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4 Omitted Variable Bias </h3>\n",
    "\n",
    "To see what line ols actually gives us, we can start by writing the regression of ability on educ:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "ability = \\gamma_0 + \\gamma_1 educ + v \\tag{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $E(v)=0$ and $cov(educ, v) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we substitute in equation (2) into equation (1):\n",
    "\n",
    "\\begin{align}\n",
    "wage &= \\beta_0 + \\beta_1 educ + \\beta_2 ability + u \\\\\n",
    "&= \\beta_0 + \\beta_1 educ + \\beta_2 (\\gamma_0 + \\gamma_1 educ + v) + u \\\\\n",
    "&= (\\beta_0 + \\beta_2 \\gamma_0) + ( \\beta_1 + \\beta_2 \\gamma_1) educ + (\\beta_2 v + u )\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now notice that we fulfilled our moment conditions needed to identify $\\beta_1$ and $\\beta_2$:\n",
    "\n",
    "$$E(\\beta_2 v + u ) = \\beta_2 E(v) + E(u) = 0$$\n",
    "\n",
    "$$cov(educ, \\beta_2 v + u ) = \\beta_2 cov(educ, v ) + cov(educ, u ) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ols will consistently estimate this new slope, $\\beta_1 + \\beta_2 \\gamma_1$.  This is the effect we want, $\\beta_1$, plus an extra term, $\\beta_2 \\gamma_1$, which we call *omitted variable bias*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Summary: When $ability$ is omitted from the regression. \n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "&\\text{What you want to estimate: }\\;  \\beta_1 = \\frac{\\partial wage}{\\partial educ} \\\\\n",
    "%\n",
    "&\\text{What you're actually estimating: } \\;     \\beta_1 + \\beta_2 \\gamma_1 = \\frac{\\partial wage}{\\partial educ} + \\frac{\\partial wage}{\\partial ability}\\frac{\\partial ability}{\\partial educ}\n",
    "\\end{align}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 5 Omitted Variable Bias: R Exercise </h3>\n",
    "\n",
    "The file htv.RData contains data from the 1991 National Longitudinal Survey of Youth, provided by Wooldridge.  All people in the sample are males age 26 to 34.  The data is interesting here, because it includes education (educ), but also a score on an ability test (abil).\n",
    "\n",
    "We will assume that the true model is,\n",
    "\n",
    "$$wage = \\beta_0 + \\beta_1 educ + \\beta_2 abil + u$$\n",
    "\n",
    "** Note: ** One problem with this analysis is that we're not really measuring ability.  $abil$ is a *proxy* for ability, not ability itself.  And there is a lot of evidence to suggest that standardized tests are not a very good proxy.  But for now, let's pretend that we really are measuring ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.1: ** Using R, estimate (1) the true model, and (2) the regression of abil on educ. Write down the expression for what omitted variable bias would be if you couldn't measure abil.  Add this omitted variable bias to the coefficient for educ to see what it would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wage ~ educ + abil, data = data)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)         educ         abil  \n",
       "    -2.5226       1.1530       0.4333  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = abil ~ educ, data = data)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)         educ  \n",
       "    -5.3890       0.5512  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(\"htv.RData\")\n",
    "\n",
    "model_true = lm(wage ~ educ + abil, data = data)\n",
    "model_true\n",
    "\n",
    "first_stage = lm(abil ~ educ, data = data)\n",
    "first_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Omitted variable bias: (Coeff on abil in primary equatmion)*(Coeff on educ in secondary equation)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Omitted Variable Bias = 0.23883496'"
      ],
      "text/latex": [
       "'Omitted Variable Bias = 0.23883496'"
      ],
      "text/markdown": [
       "'Omitted Variable Bias = 0.23883496'"
      ],
      "text/plain": [
       "[1] \"Omitted Variable Bias = 0.23883496\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paste('Omitted Variable Bias =',0.4333 *  0.5512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Estimate for Beta_1 when abil is omitted:  1.39183496'</span>"
      ],
      "text/latex": [
       "'Estimate for Beta\\_1 when abil is omitted:  1.39183496'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Estimate for Beta_1 when abil is omitted:  1.39183496'</span>"
      ],
      "text/plain": [
       "[1] \"Estimate for Beta_1 when abil is omitted:  1.39183496\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paste('Estimate for Beta_1 when abil is omitted: ',0.4333 *  0.5512 + 1.1530)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.2 ** Now confirm your previous result by fitting the model, $$wage = \\alpha_0 + \\alpha_1 educ + w$$\n",
    "Make sure your coefficient for $educ$ corresponds to what you computed in Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wage ~ educ, data = data)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)         educ  \n",
       "     -4.857        1.392  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_rest = lm(wage ~ educ, data = data)\n",
    "model_rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.3 ** What does the direction of omitted variable bias suggest about ols estimates of returns to education?  What does this suggest about the reported statistical significance of education?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Given that the omitted variable bias is positive, the ols estimates will over estimate the marginal effect of educ on wages. Furthermore it will scale the coefficient away from zero making it easier to reject the null hypothesis/gain statistical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0 The Direction of Omitted Variable Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following regressions, use your background knowledge to estimate whether omitted variable bias will drive your slope coefficient towards zero or away from zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1**  Regression: $grade = \\beta_0 + \\beta_1 attendance + u$, omitted: $time\\_studying$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First we write down both equations\n",
    "$$ grade = \\beta_0 + \\beta_1*attendance + \\beta_2*time\\_studying + u$$\n",
    "  $$ time\\_studying = \\alpha_0 + \\alpha_1*attendance +u $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If $\\beta_2 > 0$ and $\\alpha_1 >0$ then $OMVB = \\beta_2\\alpha_1 >0$ and if $\\beta_1>0$ then the OLS coefficient on $attendance$ will be scaled away from zero (more positive) gaining statistical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 6.2 ** Regression: $lifespan = \\beta_0 + \\beta_1 cigarettes + u$, omitted: $exercise$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First we write down both equations\n",
    "$$ lifespan = \\beta_0 + \\beta_1* cigarettes + \\beta_2*exercise + u$$\n",
    "$$ exercise= \\alpha_0 + \\alpha_1*cigarettes +u $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If $\\beta_2 > 0$ and $\\alpha_1 <0$ then $OMVB = \\beta_2\\alpha_1 <0$ and if $\\beta_1<0$ then the OLS coefficient on $cigarettes$ will be scaled away from zero (more negative) gaining statistical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 6.3 ** Regression: $lifespan = \\beta_0 + \\beta_1 cigarettes + u$, omitted: $time\\_socializing$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Both equations\n",
    "$$ lifespan = \\beta_0 + \\beta_1* cigarettes + \\beta_2*time\\_socializing + u$$\n",
    "  $$ time\\_socializing= \\alpha_0 + \\alpha_1*cigarettes +u $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If $\\beta_2 > 0$ and $\\alpha_1 >0$ then $OMVB = \\beta_2\\alpha_1 >0$ and if $\\beta_1<0$ then the OLS coefficient on $cigarettes$ will be scaled toward zero (less negative) losing statistical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 6.4 ** Regression: $wage = \\beta_0 + \\beta_1 grad\\_education + u$, omitted: $experience$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Both Equations\n",
    "$$ wage = \\beta_0 + \\beta_1* grad\\_education + \\beta_2*experience + u$$\n",
    "  $$ experience= \\alpha_0 + \\alpha_1*grad\\_education+u $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If $\\beta_2 > 0$ and $\\alpha_1 < 0$ then $OMVB = \\beta_2\\alpha_1 <0$ and if $\\beta_1>0$ then the OLS coefficient on attendance will be scaled toward zero (less positive) losing statistical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 6.5 ** Regression: $wage = \\beta_0 + \\beta_1 grad\\_education + u$, omitted: desire to effect $social\\_good$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Both equations \n",
    "$$ wage = \\beta_0 + \\beta_1* grad\\_education + \\beta_2*social\\_good + u$$\n",
    "  $$ social\\_good= \\alpha_0 + \\alpha_1*grad\\_education+u $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If $\\beta_2 < 0$ and $\\alpha_1 > 0$ then $OMVB = \\beta_2\\alpha_1 <0$ and if $\\beta_1>0$ then the OLS coefficient on $grad\\_education$ will be scaled toward zero (less positive) losing statistical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.0 Influential Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 7.1 ** What does it mean for a data point to have high leverage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A data point has high leverage if the value $X_i$ of that point is far away from the mean of $\\{X_j\\}_{j \\neq i}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 7.2 ** What does it mean for a data point to have high influence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A data point has high influence if removing it from the estimation while significantly change the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 7.3 ** How is it possible for a data point to have low leverage but high influence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A data point whose regressor values $X_i$ are close the mean of $\\{X_j\\}_{j=1}^n$ but whose regressand $Y_i$ value is far from the average of all other regressand values $\\{Y_j\\}_{j \\neq i}$ (excluding itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 7.4 ** How is it possible for an outlier to have low influence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If its regressor values $X_i$ are far away from the mean of $\\{X_j\\}_{j=1}^n$ but the response value is close to what would be predicted if it was excluded from estimation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
