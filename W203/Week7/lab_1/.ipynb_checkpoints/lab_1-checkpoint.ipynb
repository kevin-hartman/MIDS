{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Probability Theory\n",
    "## W203: Statistics for Data Science\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Meanwhile, at the Unfair Coin Factory...\n",
    "\n",
    "You are given a bucket that contains 100 coins.  99 of these are fair coins, but one of them is a trick coin that always comes up heads.  You select one coin from this bucket at random.  Let T be the event that you select the trick coin.  This means that $P(T) = 0.01$.\n",
    "\n",
    "a. Suppose you flip the coin $k$ times.  Let $H_k$ be the event that the coin comes up heads all $k$ times.  If you see this occur, what is the conditional probability that you have the trick coin?  In other words, what is $P(T|H_k)$.\n",
    "\n",
    "b. How many heads in a row would you need to observe in order for the conditional probability that you have the trick coin to be higher than 99%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Wise Investments \n",
    "\n",
    "You invest in two startup companies focused on data science, Company 1 and Company 2.  Let $U_i$ be the event that Company $i$ reaches unicorn status (valued at \\\\$1 billion).  Thanks to your growing expertise in this area, $P(U_1) = P(U_2) = 3/4$.  $U_1$ and $U_2$ may or may not be independent of each other.  Let random variable $X$ be the total number of companies that reach unicorn status.  X can take on the values 0, 1, and 2. \n",
    "\n",
    "a. Compute $E(X)$.\n",
    "\n",
    "b. Compute the minimum and maximum values for $var(X)$.\n",
    "\n",
    "Now suppose there are four companies, Company 1 through Company 4.  Again, let $U_i$ be the event that Company $i$ reaches unicorn status.  $P(U_i) = 3/4$ for all $i$.  Once again, let random variable $X$ be the total number of companies that reach unicorn status.\n",
    "\n",
    "c. Compute the minimum and maximum values for $var(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Broken Rulers\n",
    "\n",
    "You have a ruler of length 2 and you choose a place to break it using a uniform probability distribution.  Let random variable X represent the length of the left piece of the ruler.  X is distributed uniformly in $[0,2]$.  You take the left piece of the ruler and once again choose a place to break it using a uniform probability distribution.  Let random variable Y be the length of the left piece from the second break.\n",
    "\n",
    "a. Draw a picture of the region in the X-Y plane for which the joint density of X and Y is non-zero.\n",
    "\n",
    "b. Find the conditional expectation of $Y$ given $X$, $E(Y|X)$.\n",
    "\n",
    "c. Find the unconditional expectation of $Y$.  \n",
    "\n",
    "d. Give a complete expression for the conditional distribution of $X$, conditional on $Y$.\n",
    "\n",
    "e. Compute $cov(X,Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Concert Time\n",
    "\n",
    "You are in an online waiting room to buy a concert ticket to your favorite a cappella group: the Pitch Estimators. Suppose your waiting time in minutes is a continuous random variable $T$ with probability density function given by:\n",
    "\n",
    "$f_T(t)=\\begin{cases}\n",
    "\\frac{1}{3}e^{-\\frac{1}{3}t}, &t\\geq0\\\\\n",
    "0, &otherwise\\\\\n",
    "\\end{cases}\n",
    "$ \n",
    "\n",
    "a. Please sketch the probability density.\n",
    "\n",
    "b. Compute the **mean**, **median**, and **mode** of the waiting time distribution and mark each of these values on your sketch.  (Recall that the median is defined by the point at which the cumulative probability function equals $1/2$.  The mode is the point at which the probability density function is at its maximum.)\n",
    "\n",
    "c. If you have already been waiting for 3 minutes, what is the probability that you will continue to wait for another 3 minutes?\n",
    "\n",
    "d. Because the ticket website is so slow, you convince two friends to help you purchase a ticket more quickly.   Each goes on a different website to wait for a ticket.  If one of your friends gets a ticket before you, they will give it to you and you will not need to wait any longer.  Suppose the waiting times for the two other websites are random variables, $U$ and $V$, with probability density functions given by:\n",
    "\n",
    "$f_U(t)=\\begin{cases}\n",
    "\\frac{1}{2}e^{-\\frac{1}{2}t}, &t\\geq0\\\\\n",
    "0, &otherwise\\\\\n",
    "\\end{cases} \\qquad\n",
    "f_V(t)=\\begin{cases}\n",
    "\\frac{1}{6}e^{-\\frac{1}{6}t}, &t\\geq0\\\\\n",
    "0, &otherwise\\\\\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "Your waiting time is now the minimum of the waiting times for each of the three websites, $min(T,U,V)$.  What is your expected wait time? (Hint: First, given a time t, calculate the probability that $T>t$, $U>t$, and $V>t$)\n",
    "\n",
    "For two probability density functions g and h, we define the **Kullback-Leibler divergence** (K-L divergence) as $D(g||h)=\\int_{-\\infty}^{\\infty} g(x)\\log{\\frac{g(x)}{h(x)}} dx$.  K-L divergence comes from an Information Theory background (for those curious, you can read more at https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence ) in which we try to say \"how much information is lost\" when we try to approximate g by h (how well h approximates g). You may think of K-L divergence as measuring how different $g$ and $h$ are, but it isn't quite a distance metric because it's not symmetric. Usually, $D(g||h)\\neq D(h||g)$.\n",
    "\n",
    "**Motivation :**  KL-Divergence is a popular concept in machine learning where it is used to measure how well some model or function approximator captures a distribution. It is also closely tied to another concept known as **Mutual Information**. If instead of considering two separate random variables, we consider the K-L divergence between a product of marginal distributions and their joint distribution: $D(f_{X,Y}||f_{X}f_{Y})$ and can see it as measuring how much knowing one of the variables reduces the uncertainty about the other  (https://en.wikipedia.org/wiki/Mutual_information#Relation_to_Kullback%E2%80%93Leibler_divergence). In the context of natural language processing, suppose that $X$ is a random variable representing an occurrance of the word \"cat\" in a sentence.  Suppose $Y$ is a random variable representing an occurance of the word \"pet.\"  If $X$ and $Y$ have high mutual information, this indicates that the words tend to show up in the same sentences.\n",
    "\n",
    "e. Compute $D(f_T||f_T)$, the K-L divergence of your waiting time with itself.  (Integrate from $0$ to $\\infty$ to avoid any division-by-zero issues)\n",
    "\n",
    "f. Compute $D(f_T||f_U)$ and $D(f_T||f_V)$.\n",
    "\n",
    "g. Draw a sketch of the three distributions and write 2 or 3 sentences on how the KL divergence is reflected in what you see in the graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Probabilities for Patients\n",
    "\n",
    "You might be wondering how probability theory is applied to real world problems.  One example has to do with predicting patient outcomes based on their current state.  As you can see, there are big prizes for this sort of analysis (https://www.cmschallenge.ai/).  \n",
    "\n",
    "Consider a simple model that progresses year-by-year.   In year $i$, let $W_i$ be the event that the patient is well, $I_i$ be the event that the patient is ill, and $D_i$ be the event that the patient is dead.  Transitions can be modeled as a set of conditional probabilities.  For example the probability that a well patient is well in the next year is, $P(W_{i+1}|W_i)$.\n",
    "\n",
    "In the basic model, individuals can only stay in their current state or get sicker, so $P(W_{i+1}|I_i) = P(W_{i+1}|D_i) = P(I_{i+1}|D_i) = 0$. Dead is an abosorbing state, meaning $P(D_{i+1}|D_I)=1$.\n",
    "\n",
    "You can see this model drawn out in this paper, which propsed this as a method of clinical decision making (Med Decis Making 3:419-458, 1983). The notation is a little different for example $P(W_{i+1}|W_i)$ is written as $P_{ww}$.\n",
    "\n",
    "![alt text](Markov_diagnosis.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A patient has just returned from the hospital after a fall, They are *Well* in year 1, but given their age and risk factors, $P(W_{i+1}|W_i) = 0.2$ for all $i$.\n",
    "\n",
    "Let $L$ be the random variable representing the number of years that the patient is well.  We can write this mathematically as,\n",
    "\n",
    "$$ L = argmax_i W_i $$\n",
    "\n",
    "a. Write a complete expression for the probability mass function of $L$.\n",
    "\n",
    "b. Compute the expectation of $L$.\n",
    "\n",
    "c. Write an R function that simulates the trajectory of a single patient and returns the number of years the patient is well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Use R to simulate 1000 patient trajectories and find the sample mean of years of wellness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. The use of a walker increases the likelihood of staying well so that $P(W_{i+1}|W_i) = 0.5$ for all $i$.   How many years will a walker add to the expected time being well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we match these models to clinical data we often have to account for varying time windows based on available data.  Consider the following scenarios:\n",
    "\n",
    "f. In study number 1, 100 patients were all well in year 1, and 80 of them were well 2 years later (in year 3).  Assuming the transition probabilities are constant, what is $P(W_{i+1}|W_i)$?\n",
    "\n",
    "g. In study number 2, 100 patients were all well in year 1, and 40 of them were well 6 years later (in year 7).  Assuming the transition probabilities are constant, what is $P(W_{i+1}|W_i)$?\n",
    "\n",
    "h. Notice that both study 1 and study 2 have an average of 10 patients becoming unwell per year.  If you got different answers for f. and g., explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Now suppose $P(W_{i+1}|W_i) = 0.2$ and $P(I_{i+1}|I_i) = 0.2$ for all $i$.  Compute the expected number of years that a patient will be alive. look at the diagram to appreciate that patients can either stay the same or get sicker. The patients must traverse the Ill state before death so $P(D_{i+1}|W_i) = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
