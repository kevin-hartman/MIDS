{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Unit 7 Live Session </center> </h1>\n",
    "<h3> W203 Instructional Team </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Estimation </h2>\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1teoq6AS-Oj0J0hkSIV8fBFvPSyX93il0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 0.1 Class Announcements </h3>\n",
    "1. Announcement 1\n",
    "2. Announcement 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 0.2 Getting to This Document</h3>\n",
    "\n",
    "If you have not cloned the unit_7_ls repo yet then on the command line\n",
    "\n",
    "1. git clone https://github.com/w203-spring-19/unit_7_ls.git \n",
    "\n",
    "2. cd unit_7_ls\n",
    "\n",
    "\n",
    "\n",
    "If you have cloned this repo already then on the command line\n",
    "\n",
    "1. cd unit_7_ls\n",
    "\n",
    "2. git fetch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1 Introduction and Review </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 1.1 Generalization </h4>\n",
    "\n",
    "The whole point of gathering data from a given population and calculating the value of a statistic based on those observations is so that whatever conclusions we draw from the sample data will apply to the larger population that we are sampling from. i.e. the results of our analysis *generalize* to the larger population.\n",
    "\n",
    "The ability to generalize from the analysis conducted on a sample $\\{X_i\\}_{i=1}^n$ with a statistic $f(\\cdot)$, depends more or less on two things,\n",
    "\n",
    "* The manner in which the analysis is conducted, (number of comparisons, stopping rules, sample splitting ...) \n",
    "\n",
    "\n",
    "* The sampling distribution of $f(X_1,X_2, \\ldots , X_n)$\n",
    "\n",
    "\n",
    "We will discuss the first bullet point in our unit dedicated to reproducibility, so for now we will assume that the analysis is conducted appropriately and yet again focus on the sampling distribution. Recall that   \n",
    "\n",
    "$$  \n",
    "\\begin{align*}\n",
    "\\text{Sampling Distribution of $f(X_1,\\ldots,X_n)$} &= \\text{Characteristics of Underlying Random Variable $X$} \\\\\n",
    "& \\hspace{1cm}+ \\text{Properties of Statistic $f(\\cdot)$} \\\\\n",
    "& \\hspace{1cm} + \\text{Sampling Method for $\\{X_i\\}_{i=1}^n$  }\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "For example: \n",
    "\n",
    "1.) **If**: $E(|X_i|) < \\infty$, **and**  $f(X_1,X_2, \\ldots,X_n) = n^{-1}\\sum_{i=1}^n X_i \\; $ **and** $\\{X_{i}\\}_{i=1}^n$ is an i.i.d random sample **then** the LLN tells us that.   \n",
    "\n",
    "$$ \\left| n^{-1}\\sum_{i=1}^n X_i - E(X) \\right| \\stackrel{p}{\\rightarrow} 0 $$\n",
    "\n",
    "Meaning the value of $n^{-1}\\sum_{i=1}^n X_i$ gets closer and closer (in probability) to the true (population) value of $E(X)$ as the number of observations $n$ increases. In words under these conditions the value of a sample average $\\overline{X}_n$ generalizes to the expected value of the population of $X$ because the LLN provides a connection between them. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 1.2 Estimation </h4> \n",
    "\n",
    "We now have the tools to be able to take data (e.g. $\\{X_i\\}_{i=1}^n$)  and use it to infer information about the (joint) distribution of the underlying random variable ($X$). \n",
    "\n",
    "Generally this means that we will use the data to calculate point estimates for the parameters of the distribution of the underlying random variable. In practice we are often most interested in $E(X)$ , $V(X)$ , or $Cov(X,Y)$ etc.\n",
    "\n",
    "There are a number of techniques that you can use to develop a valid estimator for a parameter. These techniques vary in terms of the principle used to arrive at the estimator and the strength of the assumptions needed to support it. \n",
    "\n",
    "However, All of these estimators are statistics meaning they are functions of the data $\\{X_i\\}_{i=1}^n$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 1.3 Evaluating and Comparing Estimators </h4>\n",
    "\n",
    "Given the multiplicity of valid estimators for a parameter we need a frame work to evaluate them in terms of their sampling distribution.\n",
    "\n",
    "Suppose $\\hat{\\theta}_1$ and $\\hat{\\theta}_2$ are two valid estimators for a parameter $\\theta$. We will compare these estimators in terms of two characteristics their sampling distributions.\n",
    "\n",
    "* Bias: $E(\\hat{\\theta}_j - \\theta)$\n",
    "\n",
    "* Variance: $V(\\hat{\\theta}_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1_CrGHHT8UDjuUZqAGo7IFi02Iu6aCHLX\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is the difference between the expected value of the estimator $E(\\hat{\\theta}_j)$ and $\\theta$. Variance, as we already know, is how spread out the values of the estimator are around its expected value.\n",
    "\n",
    "As a general (meaning many exceptions exist) guideline\n",
    "\n",
    "* If $E(\\hat{\\theta}_1 - \\theta) = 0 $ and  $E(\\hat{\\theta}_2 - \\theta) > 0 $ then the unbiased estimator $\\theta_1$ is preferred to $\\theta_2$ \n",
    "\n",
    "* If $E(\\hat{\\theta}_1 - \\theta) = E(\\hat{\\theta}_2 - \\theta) = 0 $ then the estimator with the smallest variance is preferred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2 Discussion of Point Estimation, MOM, and The Method of ML </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1 ** What is point estimation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.2 ** In your own words, describe how the method of moments is used to estimate the unknown parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.3 ** In your own words, describe how the method of ML is used to estimate the unknown parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.4 ** Why do data scientists need to understand likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3 Warm-up: Optimization in R </h3>\n",
    "\n",
    "The method of maximum likelihood requires an optimization routine. For a few very simple probability models, a closed-form solution exists and the MLE can be derived by hand. In most cases, however, hand-derivation will be too tedious, if at all possible, and a numerical computation technique is needed.\n",
    "\n",
    "Numerical computation techniques often require some sort of optimization. For our purpose in this live session, we will focus on the practice of maximizing likelihood functions using R.\n",
    "\n",
    "There are many optimizers in R(), including optimize(), optim(), and optimx().  I will use optimize() which is very simple to use, but only works for one dimension.\n",
    "\n",
    "As always, I encourage you to read the documentation of the functions you are using: [optim](http://stat.ethz.ch/R-manual/R-devel/library/stats/html/optim.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Optomization Example: ** \n",
    "\n",
    "Suppose that a firm's revenue $r$ from selling a product is related to price $p$ as follows:\n",
    "$$ \n",
    "r = - p^2 + p + 2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.1.1 ** Explain how you would use calculus to find the maximizing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.1.2 ** Solve this numerically in *R*, using the *optimize()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 4 Maximum Likelihood Estimation of Bernoulli Random Variables </h4>\n",
    "Suppose that youâ€™ve got a sequence of values $$ {1, 0, 0, 1, 0, 1, 1, 1, 1, 1} $$ which, say, indicates whether a printer jams each day, for the last 10 business days. Business Question: What is the probability ($p$) that the printer jams in any given day?\n",
    "\n",
    "It resembles draws from a Bernoulli disribution. However, even if we want to model this as a Bernoulli distribution, we do not know what the value of the parameter, $p$, is.\n",
    "\n",
    "Let's review the steps to find the maximum likelihood estimate for $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.1 ** Define your random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.2 ** Write down the likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.3 ** (Optional) take the log of the likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.4 ** Maximize (the log of) likelihood using calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.5 ** Alternately, maximize the likelihood numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 5 MLE for Poisson Random Variables </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A Poisson process is a simple model that statisticians use to describe how events occur over time.  Imagine that time stretches out on the x-axis, and each event is a single point on this axis.* \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1s0IcnPDYbobtNp7VOUnp83IfCZGozrXG\">\n",
    "\n",
    "\n",
    "The key feature of a Poisson process is that it is *memoryless*.  Loosely speaking, the probability that an event occurs in any (differentially small) instant of time is a constant.  It doesn't depend on how long ago the previous event was, nor does it depend on when future events occur.\n",
    "\n",
    "Data scientists might use a Poisson process (or more complex variations) to represent:\n",
    "\n",
    "  - The scoring of goals in a world cup match\n",
    "  - The arrival of packets to an internet router\n",
    "  - The arrival of customers to a website\n",
    "  - The failure of servers in a cluster\n",
    "  - The time between large meteors hitting the Earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand a Poisson process, imagine an experiment in which you observe the arrival of cars at an intersection.  Assume that the probability density that a car arrives in a differentially small interval of time is just a constant.  The intersection is no more busy during the day than during the night.  \n",
    "\n",
    "Moreover, the probability density that a car arrives at a particular instant does not depend on when the previous cars arrived, not when future cars are going to arrive.  Each moment of time is independent.  This is an example of what we call a memory-less process.\n",
    "\n",
    "Next, suppose we use a camera to record the intersection for a particular length of time, and we write down the number of cars that arrive in that interval.  This is what we call a Poisson random variable.  It has a well-known probability mass function, given by,\n",
    "\n",
    "$$\n",
    "f(x|\\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n",
    "$$\n",
    "\n",
    "Here, $\\lambda$ is a parameter, which represents the mean number of cars in an interval.  (You may take the expectation to check this).  The following graph, \"freely\" borrowed from Wikipedia shows the probability mass function for different values of $\\lambda$.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=13rbRe-0Hhe3tz98EpSAJAzyBhzu0sHO9\">\n",
    "\n",
    "Suppose we take a random sample, and the data appears as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data\n",
       " 1  2  3  4  5  6  7  9 10 24 \n",
       "54 69 38 14 14  6  1  2  1  1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = c(2,6,2,1,3,3,4,4,24,1,5,4,5,1,2,2,5,2,1,5,2,1,2,9,9,1,3,2,1,1,3,1,3,2,2,4,1,1,5,3,3,2,2,1,1,1,5,1,3,1,1,1,1,2,2,4,2,1,2,2,3,1,2,6,2,2,3,2,3,5,1,3,2,5,2,1,3,2,1,2,4,2,6,1,2,2,3,5,2,1,4,2,2,1,3,2,2,4,1,1,1,1,2,3,5,1,2,2,3,1,4,1,3,2,2,2,2,2,2,3,3,1,1,2,2,4,1,5,2,7,5,2,3,2,5,3,1,2,1,1,2,3,1,5,3,4,6,3,3,2,2,1,2,2,4,2,3,4,3,1,6,3,1,2,3,2,2,3,1,1,1,1,1,10,3,2,1,1,3,2,2,3,1,1,2,2,2,4,2,2,3,3,6,1,3,2,3,2,2,2)\n",
    "table(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.1 ** Define your random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.2 ** Write down the likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.3 **  Take the log of the likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.4 ** Maximize (the log of) likelihood using calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.5 ** Maximize likelihood numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
