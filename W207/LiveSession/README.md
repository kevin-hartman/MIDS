# Preparing for Live Sessions 

The live session presentation content is located [[https://drive.google.com/drive/u/0/folders/1Kcy7uKLwSJYqlXDWRz3rlfVXc88fbn7R][here]].

The reference notebooks used during live session are located [[https://drive.google.com/drive/u/0/folders/1aoxZxDQa_uGEV4D2EyuUj-2van70wvKo][here]].

*Topics for class*

| Week  | Topic |
|------|----------| 
|Week 1 | [Introduction](#week-1-introduction) | 
|Week 2 | [Problem Setup and Nearest Neighbors](#week-2-problem-setup-and-nearest-neighbors) |  
|Week 3 | [Supervised Learning I: Naive Bayes](#week-3-Supervised-Learning-I-Naive-Bayes) |
|Week 4 | [Supervised Learning II: Decision Trees](#week-4-Supervised-Learning-II-Decision-Trees) |
|Week 5 | [Supervised Learning III: Regression](#week-5-Supervised-Learning-III-Regression) |
|Week 6 | [Supervised Learning IV: More Linear Models](#week-6-Supervised-Learning-IV-More-Linear-Models) |
|Week 7 | [Supervised Learning V: Neural Networks](#week-7-Supervised-Learning-V-Neural-Networks) |
|Week 8 | [Supervised Learning VI: SVMs, Choosing Classifiers, Speech Recognition](#week-8-Supervised-learning-VI-SVMs-Choosing-Classifiers-Speech-Recognition) |
|Week 9 | [Unsupervised Learning I: Cluster Analysis](#week-9-Unsupervised-learning-I-Cluster-Analysis) |
|Week 10 | [Unsupervised Learning II: Expectation Maximization](#week-10-Unsupervised-Learning-II-Expectation-Maximization) |
|Week 11 | [Unsupervised Learning III: Dimensionality Reduction](#week-11-Unsupervised-learning-III-Dimensionality-Reduction) | 
|Week 12 | [Network Analysis](#week-12-Network-Analysis) |
|Week 13 | [Recommender Systems](#week-13-Recommender-systems) |
|Week 14 | [Wrap-Up](#week-14-Wrap-Up) |



# Week 1: Introduction
 * Overview of machine-learning applications
 * Brief history
 * Fundamentals of machine learning
 * [[https://drive.google.com/open?id=1Nbk3T4Mn879M6FPxn2BUcYx_K7hPGFZm][Link to Week 1 Presentation]]

# Week 2: Problem Setup and Nearest Neighbors
 * Why prediction?
 * Training and test data; cross-validation
 * Evaluation and baselines
 * Generalization and overfitting: linear models vs. nearest neighbors
 * K-nearest neighbors, distance metrics
 * Case study: real estate value, digit classification
 * [[https://drive.google.com/open?id=1qsTtoJuvp3oonVZx6S5iLa9iyfm7TVHn][Link to Week 2-3 Presentation]]

# Week 3: Supervised Learning I: Naive Bayes
 * Probability review: Random variables, Independence, Bayes rule
 * Generative models and Naive Bayes
 * Maximum likelihood estimation and smoothing
 * Case study: spam classification
 * [[https://drive.google.com/open?id=1qsTtoJuvp3oonVZx6S5iLa9iyfm7TVHn][Link to Week 2-3 Presentation]]

# Week 4: Supervised Learning II: Decision Trees
 * Decision Trees
 * Information Gain
 * Overfitting and pruning
 * Ensemble methods
 * Case study: customer churn, fuel efficiency

# Week 5: Supervised Learning III: Regression
 * Review of linear regression
 * Inference and prediction
 * Logistic regression and classification
 * Extensions and advanced topics

# Week 6: Supervised Learning IV: More Linear Models
 * Gradient descent for regression
 * Regularization

# Week 7: Supervised Learning V: Neural Networks
 * The perceptron
 * State of the art: neural networks for speech recognition

# Week 8: Supervised Learning VI: SVMs, Choosing Classifiers, Speech Recognition
 * Support Vector Machines
 * Comparing classifiers: performance, training speed, model size, interpretability
 * Feature engineering tips
 * Speech recognition overview

# Week 9: Unsupervised Learning I: Cluster Analysis
 * What if our data donâ€™t have labels?
 * Distance metrics (Hamming, Euclidean, Cosine, Mahalanobis)
 * K-means clustering
 * Hierarchical clustering

# Week 10: Unsupervised Learning II: Expectation Maximization
 * Expectation-Maximization and the idea of hidden variables
 * Basics of Gaussian Mixture Models
 * Case study: speaker identification

# Week 11: Unsupervised Learning III: Dimensionality Reduction
 * Motivation
 * Dimensionality reduction
 * Principal Component Analysis
 * Case study: Eigenfaces
 * Other methods for dimensionality reduction: SVD, NNMF, LDA

# Week 12: Network Analysis
 * Graph algorithms (pagerank).
 * Network link predictions.
 * Scaling and other challenges.

# Week 13: Recommender Systems
 * Motivation
 * The Netflix challenge
 * Content-based methods
 * Learning features and parameters
 * Nearest-neighbor CF

# Week 14: Wrap-Up
 * Topics beyond the scope of this course
 * What your instructors do
