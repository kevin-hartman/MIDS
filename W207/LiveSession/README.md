# Preparing for Live Sessions 

*Topics for class*

| Week  | Topic |
|------|----------| 
|Week 1 | [Introduction](#week-1-introduction) | 
|Week 2 | [Problem Setup and Nearest Neighbors](#week-2-problem-setup-and-nearest-neighbors) |  
|Week 3 | [Quantifying uncertainty](#week-3-quantifying-uncertainty) |
|Week 4 | [Blocking and Clustering](#week-4-blocking-and-clustering) |
|Week 5 | [Covariates and Regression](#week-5-covariates-and-regression) |
|Week 6 | [Regression; Multi-Factor Experiments](#week-6-regression-multi-factor-experiments) |
|Week 7 | [Heterogeneous Treatment Effects ](#week-7-heterogeneous-treatment-effects) |
|Week 8 | [Noncompliance](#week-8-noncompliance) |
|Week 9 | [Spillovers](#week-9-spillovers) |
|Week 10 | [Common problems and diagnostics](#week-10-common-problems-and-diagnostics) |
|Week 11 | [Causality from Observational Data (IV, RD)](#week-11---causality-from-observational-data-iv-rd) | 
|Week 12 | [Attrition, Mediation, Generalizability](#week-12---attrition-mediation-generalizability) |
|Week 13 | [Examples of Experiments](#week-13---examples-of-experiments) |
|Week 14 | [Student Presentations](#student-presentations-plan-on-15-20-min-plus-time-for-questions) |



# Week 1: Introduction
 * Overview of machine-learning applications
 * Brief history
 * Fundamentals of machine learning

# Week 2: Problem Setup and Nearest Neighbors
 * Why prediction?
 * Training and test data; cross-validation
 * Evaluation and baselines
 * Generalization and overfitting: linear models vs. nearest neighbors
 * K-nearest neighbors, distance metrics
 * Case study: real estate value, digit classification

# Week 3: Supervised Learning I: Naive Bayes
 * Probability review: Random variables, Independence, Bayes rule
 * Generative models and Naive Bayes
 * Maximum likelihood estimation and smoothing
 * Case study: spam classification

# Week 4: Supervised Learning II: Decision Trees
 * Decision Trees
 * Information Gain
 * Overfitting and pruning
 * Ensemble methods
 * Case study: customer churn, fuel efficiency

# Week 5: Supervised Learning III: Regression
 * Review of linear regression
 * Inference and prediction
 * Logistic regression and classification
 * Extensions and advanced topics

# Week 6: Supervised Learning IV: More Linear Models
 * Gradient descent for regression
 * Regularization

# Week 7: Supervised Learning V: Neural Networks
 * The perceptron
 * State of the art: neural networks for speech recognition

# Week 8: Supervised Learning VI: SVMs, Choosing Classifiers, Speech Recognition
 * Support Vector Machines
 * Comparing classifiers: performance, training speed, model size, interpretability
 * Feature engineering tips
 * Speech recognition overview

# Week 9: Unsupervised Learning I: Cluster Analysis
 * What if our data donâ€™t have labels?
 * Distance metrics (Hamming, Euclidean, Cosine, Mahalanobis)
 * K-means clustering
 * Hierarchical clustering

# Week 10: Unsupervised Learning II: Expectation Maximization
 * Expectation-Maximization and the idea of hidden variables
 * Basics of Gaussian Mixture Models
 * Case study: speaker identification

# Week 11: Unsupervised Learning III: Dimensionality Reduction
 * Motivation
 * Dimensionality reduction
 * Principal Component Analysis
 * Case study: Eigenfaces
 * Other methods for dimensionality reduction: SVD, NNMF, LDA

# Week 12: Network Analysis
 * Graph algorithms (pagerank).
 * Network link predictions.
 * Scaling and other challenges.

# Week 13: Recommender systems
 * Motivation
 * The Netflix challenge
 * Content-based methods
 * Learning features and parameters
 * Nearest-neighbor CF

# Week 14: Wrap-Up
 * Topics beyond the scope of this course
 * What your instructors do
